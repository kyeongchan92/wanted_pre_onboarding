{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"wanted_pre_onboarding.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPYqBe8WZQXkkzjLjP3FrD5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import re\n","import math\n","import numpy as np\n","from collections import Counter"],"metadata":{"id":"AUdW59uM5UKT","executionInfo":{"status":"ok","timestamp":1644396473052,"user_tz":-540,"elapsed":10,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# 문제 1"],"metadata":{"id":"1xKQrn7Qg0kN"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"-MuMviHd3_Gr","executionInfo":{"status":"ok","timestamp":1644396478126,"user_tz":-540,"elapsed":4,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"outputs":[],"source":["class Tokenizer():\n","    def __init__(self):\n","        self.word_dict = {'oov': 0}\n","        self.fit_checker = False\n","\n","    def preprocessing(self, sequences):\n","        result = []\n","        for s in sequences:\n","            rm_special = re.sub(r'[^a-zA-Z0-9 ]', '', s.lower())  # 소문자로 바꾼 후 문자, 숫자, 공백 아닌 것은 삭제\n","            result.append(rm_special.split())  # white space 기준으로 split\n","\n","        return result\n","\n","    def fit(self, sequences):\n","        self.fit_checker = False\n","\n","        tokens = self.preprocessing(sequences)\n","        wordnum = 1\n","        for s in tokens:\n","            for word in s:\n","                if word not in self.word_dict:  # 사전에 없는 단어이면 추가\n","                    self.word_dict[word] = wordnum\n","                    wordnum += 1\n","\n","        self.fit_checker = True\n","\n","    def transform(self, sequences):\n","        result = []\n","        tokens = self.preprocessing(sequences)\n","\n","        if self.fit_checker:\n","            for s in tokens:\n","                #  word_dict에 w가 있으면 word_dict[w]로 치환. 없으면 word_dict['oov']로 치환.\n","                result.append([self.word_dict[w] if w in self.word_dict else self.word_dict['oov'] for w in s])\n","            return result\n","        \n","        else:\n","            raise Exception(\"Tokenizer instance is not fitted yet.\")\n","\n","        \n","    def fit_transform(self, sequences):\n","        self.fit(sequences)\n","        result = self.transform(sequences)\n","\n","        return result"]},{"cell_type":"markdown","source":["# 문제 2"],"metadata":{"id":"L4j6ri9Bg3vF"}},{"cell_type":"code","source":["class TfidfVectorizer:\n","    def __init__(self, tokenizer):\n","        self.tokenizer = tokenizer\n","        self.fit_checker = False\n","\n","    def fit(self, sequences):\n","        # 입력 문장들을 이용해 IDF 행렬을 만드는 함수입니다.\n","        tokenized = self.tokenizer.fit_transform(sequences)\n","\n","        s_len = len(tokenized)  # 문장의 개수\n","        token_len = len(self.tokenizer.word_dict)  # token의 개수\n","\n","        self.idf = []\n","        for t in range(token_len):  # 모든 토큰에 대하여\n","            df = 0\n","            for s in tokenized:\n","                df += t in s  # 토큰이 문장에 포함되면 document frequency +1\n","            self.idf.append(math.log(s_len / (1 + df)))  # idf 계산하여 append\n","\n","        self.fit_checker = True\n","\n","    \n","    def transform(self, sequences):\n","        # fit()에서 만든 IDF 행렬과 tf-idf 식을 이용해 TF-IDF 행렬을 만드세요\n","        if self.fit_checker:\n","            tokenized = self.tokenizer.transform(sequences)\n","            s_len = len(tokenized)  # 문장의 개수\n","            token_len = len(self.tokenizer.word_dict)  # token의 개수\n","\n","            self.tfidf_matrix = np.zeros((s_len, token_len), dtype='f')  # tfidf 행렬 생성\n","            for si, s in enumerate(tokenized):\n","                counter = Counter(s)\n","                for t in counter:\n","                    self.tfidf_matrix[si][t] += 1  # [문장번호][토큰번호] 위치에 +1\n","            \n","            self.tfidf_matrix *= self.idf  # 공식에 따라 tf와 idf 곱함, idf는 broadcasting\n","\n","            return self.tfidf_matrix\n","        else:\n","            raise Exception(\"TfidfVectorizer instance is not fitted yet.\")\n","\n","\n","    def fit_transform(self, sequences):\n","        self.fit(sequences)\n","        return self.transform(sequences)"],"metadata":{"id":"rgj1E0BpQ7PK","executionInfo":{"status":"ok","timestamp":1644396478127,"user_tz":-540,"elapsed":4,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"execution_count":4,"outputs":[]}]}